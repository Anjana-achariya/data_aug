{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4X_0be9uM7m",
        "outputId": "d2066a70-ed00-4c20-ba9a-91ea41225a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Data augmentation is a technique used to increase the size of a dataset.Data augmentation is the process of artificially generating new data from existing data, primarily to train new machine learning models.\n",
            "\n",
            "Augmented Text (Synonyms):\n",
            "data augmentation be angstrom technique use to addition the size of angstrom dataset.Data augmentation be the procedure of artificially generate new data from exist data, chiefly to train new machine learning models.\n"
          ]
        }
      ],
      "source": [
        "import nlpaug.augmenter.word as naw\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "original_text = \"Data augmentation is a technique used to increase the size, of a dataset.Data augmentation is the process of artificially generating new data from existing data, primarily to train new machine learning models.\"\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = [] #empty list to store sets of synonyms\n",
        "    for syn in wordnet.synsets(word): #wordnet - dictionary usages, synsets - sets of synonyms\n",
        "        for lemma in syn.lemmas(): # lemmas - single synonym\n",
        "            synonyms.append(lemma.name())\n",
        "    return synonyms\n",
        "\n",
        "def augment_with_synonyms(text):\n",
        "    augmented_text = []\n",
        "    words = text.split() # splits words , remove whitespaces\n",
        "    for word in words:\n",
        "        synonyms = get_synonyms(word)\n",
        "        if synonyms:\n",
        "            augmented_text.append(synonyms[0])  # use only one/first synonym from the list= synonyms\n",
        "        else:\n",
        "            augmented_text.append(word)\n",
        "    return ' '.join(augmented_text) # join the splitted words\n",
        "\n",
        "augmented_text_synonyms = augment_with_synonyms(original_text)\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(original_text)\n",
        "\n",
        "print(\"\\nAugmented Text (Synonyms):\")\n",
        "print(augmented_text_synonyms)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "original_text = \"Data augmentation is a technique used to increase the size of a dataset.\"\n",
        "\n",
        "aug_char = nac.RandomCharAug(action=\"insert\") # to generate random character and insert , delete, substitute, swap\n",
        "augmented_text_char = aug_char.augment(original_text)\n",
        "\n",
        "aug_word = naw.RandomWordAug() # to generate random word based on the existing dataset\n",
        "augmented_text_word = aug_word.augment(original_text)\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(original_text)\n",
        "\n",
        "print(\"\\nAugmented Text (Character-level):\")\n",
        "print(augmented_text_char)\n",
        "\n",
        "print(\"\\nAugmented Text (Word-level):\")\n",
        "print(augmented_text_word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8udUIN4KFJw",
        "outputId": "7726474e-c1de-4f89-856a-4d4e84c3eaca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Data augmentation is a technique used to increase the size of a dataset.\n",
            "\n",
            "Augmented Text (Character-level):\n",
            "['xDatha aBuYgLmentaution is a techn!iqsufe used to increase the sMilze of a daXtafseut.']\n",
            "\n",
            "Augmented Text (Word-level):\n",
            "['Data a technique used to increase a dataset.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I08xIU1CvrHD",
        "outputId": "fd333a57-947d-49a9-d07c-6f6c0ab76b40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QjF2wcduzC4",
        "outputId": "bfce2024-8faf-4457-d140-2a9d59af2e90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nlpaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ3Yi299uiY1",
        "outputId": "38632731-a3a6-43f8-8e77-7bc5a8e7870b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/410.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/410.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ]
    }
  ]
}