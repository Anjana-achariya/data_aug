{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh0ZqEGQ0PCq",
        "outputId": "850a9fe8-4807-4251-ac73-aceb0e1edb2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (150, 4) (150,)\n",
            "Augmented dataset shape: (15150, 4) (15150,)\n"
          ]
        }
      ],
      "source": [
        "# data augmentation - numerical values\n",
        "\n",
        "from sklearn.datasets import load_iris #importing inbuilt dataset\n",
        "from sklearn.utils import shuffle # importing shuffle to shuffle the dataset so there exist no bias\n",
        "import numpy as np  # for array\n",
        "\n",
        "iris = load_iris() #4 loading the dataset\n",
        "X, y = iris.data, iris.target  #5 # assigning feature and target\n",
        "\n",
        "X, y = shuffle(X, y, random_state=42) #6\n",
        "# shuffle the dataset\n",
        "# random state = 0 ,traing and testing will differ each time while running the model\n",
        "# random state = 42 , training and testing set won't differ\n",
        "\n",
        "def augment_data(X, y, noise_level=0.1, num_augmented_samples=100): #7\n",
        "  #defining a function to generate random samples based on the existing dataset\n",
        "  # noise level = difference from the existing data i.e standard deviation\n",
        "  # range (0-1), 0.1 = 10%\n",
        "\n",
        "    augmented_X = [] #8 # empty list to store generated data\n",
        "    augmented_y = [] #9\n",
        "    # empty list to store duplicate data . Y is not newly generated ,its replicated\n",
        "\n",
        "    for i in range(num_augmented_samples): #10\n",
        "\n",
        "        noisy_X = X + np.random.normal(loc=0.0, scale=noise_level, size=X.shape) #11\n",
        "\n",
        "      # generated values as gaussian distribution\n",
        "      # loc = mean\n",
        "      # scale = standard deviation\n",
        "\n",
        "        augmented_X.append(noisy_X) #12 # join augmented dataset to existing dataset\n",
        "        augmented_y.append(y) #13\n",
        "\n",
        "\n",
        "\n",
        "    augmented_X = np.array(augmented_X) #14 # convert into array\n",
        "    augmented_y = np.array(augmented_y) #15\n",
        "\n",
        "    augmented_X = augmented_X.reshape(-1, X.shape[1]) #16 # converting into 1D array\n",
        "    augmented_y = augmented_y.reshape(-1,) #17\n",
        "\n",
        "\n",
        "    augmented_X = np.vstack((X, augmented_X))  #18 #vertical stacking\n",
        "    augmented_y = np.hstack((y, augmented_y))#19 horizontal stacking of data\n",
        "\n",
        "    return augmented_X, augmented_y\n",
        "\n",
        "\n",
        "augmented_X, augmented_y = augment_data(X, y, noise_level=0.1, num_augmented_samples=100) #21 call the function\n",
        "print(\"Original dataset shape:\", X.shape, y.shape)\n",
        "print(\"Augmented dataset shape:\", augmented_X.shape, augmented_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(augmented_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z0_LRrQ1oKu",
        "outputId": "3bff4621-f5e0-4382-e576-4b4836b26bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.1        2.8        4.7        1.2       ]\n",
            " [5.7        3.8        1.7        0.3       ]\n",
            " [7.7        2.6        6.9        2.3       ]\n",
            " ...\n",
            " [5.81559078 3.94052537 1.06547414 0.22574002]\n",
            " [5.7795945  2.503208   4.20609371 1.32015378]\n",
            " [7.18410471 3.07714388 5.90262915 2.04645939]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "augmented_df = pd.DataFrame(augmented_X, columns=iris.feature_names) #converting into dataframe\n",
        "augmented_df['target'] = augmented_y\n",
        "\n",
        "print(augmented_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMuod9YtHOl8",
        "outputId": "213f0743-1f73-4787-a6bb-daa3a719e09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                6.1               2.8                4.7               1.2   \n",
            "1                5.7               3.8                1.7               0.3   \n",
            "2                7.7               2.6                6.9               2.3   \n",
            "3                6.0               2.9                4.5               1.5   \n",
            "4                6.8               2.8                4.8               1.4   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       0  \n",
            "2       2  \n",
            "3       1  \n",
            "4       1  \n"
          ]
        }
      ]
    }
  ]
}